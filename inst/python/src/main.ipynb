{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Permute, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, concatenate, Activation, GRU, SimpleRNN\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow  as tf\n",
    "import pickle\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.constants import NB_CLASSES_LIST\n",
    "from model_training.exp_utils import train_model, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dynamic_lstmfcn(NB_CLASS, NUM_CELLS=128):\n",
    "    ip = Input(shape=(1, None))\n",
    "    x = Permute((2, 1))(ip)\n",
    "    x = LSTM(NUM_CELLS)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "    x = Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    out = Dense(NB_CLASS, activation='softmax',kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    model = Model(ip, out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs           = 25\n",
    "LR               = 5e-5 \n",
    "batch_size       = 512 \n",
    "N_TRIALS         = 25\n",
    "TRAINING         = True\n",
    "for trial_no in range(1,N_TRIALS+1):\n",
    "    seed = randint(0,1e3)\n",
    "    tf.random.set_seed(seed)\n",
    "    dataset_map      = [('Dataset-C/TRIAL-{}'.format(trial_no),0),('Dataset-W/TRIAL-{}'.format(trial_no),1)]\n",
    "    base_log_name    = '%s_%d_cells_new_datasets.csv'\n",
    "    base_weights_dir = '%s_%d_cells_weights/'\n",
    "    normalize_dataset = False\n",
    "    MODELS = [('dynamic_lstmfcn',generate_dynamic_lstmfcn),]\n",
    "    CELLS  = [128]\n",
    "    for model_id, (MODEL_NAME, model_fn) in enumerate(MODELS):\n",
    "        for cell in CELLS:\n",
    "            for dname, did in dataset_map:\n",
    "                NB_CLASS            = NB_CLASSES_LIST[did]\n",
    "                K.clear_session()                    \n",
    "                weights_dir = base_weights_dir % (MODEL_NAME, cell)\n",
    "                os.makedirs('weights/' + weights_dir,exist_ok=True)\n",
    "                dataset_name_ = weights_dir + dname\n",
    "                model = model_fn(NB_CLASS, cell)\n",
    "                print('*' * 20, \"Training model %s for dataset %s\" % (MODEL_NAME,dname), '*' * 20)\n",
    "                if(TRAINING):\n",
    "                    model,history = train_model(model, did, dataset_name_, epochs=epochs, batch_size=batch_size,normalize_timeseries=normalize_dataset,learning_rate=LR)\n",
    "                    print(history)\n",
    "                print('--' * 20, \"Evaluating model %s for dataset %s\" % (MODEL_NAME,dname), '*' * 20)\n",
    "                acc = evaluate_model(model, did, dataset_name_, batch_size=batch_size,normalize_timeseries=normalize_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_env",
   "language": "python",
   "name": "tf2_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}